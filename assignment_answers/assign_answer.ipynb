{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Add a new service endpoint to receive the image and the desired threshold and return  the list of predictions.\n",
        "\n",
        "The service has been implemented using FastAPI and has been updated in the repository."
      ],
      "metadata": {
        "id": "7V41upy8UE_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Write a new adapter for ObjectCountRepo to persist data using a relational (MySQL or PostgreSQL) database.\n",
        "\n",
        "The code in the exsisting repository has been updated to incorporate the use of mySQL in the script."
      ],
      "metadata": {
        "id": "nj3OM1KdUi6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Review the rest of the source code and propose some improvements that you would make in the code, the setup instructions, the tests,...\n",
        "\n",
        "These are my suggestions:\n",
        "\n",
        "1.The instructions for downloading the model in the README.md file need to be modified. Specifically, \"mkdir -p tmp/model/1\" should be added before the second step.\n",
        "\n",
        "2.Adding docstrings and comments within the code can help make it easier to understand.\n",
        "\n",
        "3.The version \"intel/intel-optimized-tensorflow-serving:2.3.0\" mentioned in the \"Setup and Run Tensorflow Serving\" section of the README.md file is not available. Additionally, attempting to pull another version results in an error in prediction.\n",
        "\n",
        "4.Incorporating a logger into the code can simplify the process of identifying errors.\n",
        "\n",
        "5.Implementing a try-except block within classes is a good approach.\n",
        "\n",
        "6. Docker Compose allows for the easy deployment of multi-container Docker applications, simplifying the process of managing and running services."
      ],
      "metadata": {
        "id": "8_aYB0_hU5Jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Implement at least one of the proposed improvements"
      ],
      "metadata": {
        "id": "fmUKk2kkVtfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Suggestion 1) In README.md file Downloading the model steps to be modified. \"mkdir -p tmp/model/1\" this should be the second step.'''\n",
        "\n",
        "wget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/rfcn_resnet101_fp32_coco_pretrained_model.tar.gz\n",
        "mkdir -p tmp/model/1\n",
        "tar -xzvf rfcn_resnet101_fp32_coco_pretrained_model.tar.gz -C tmp\n",
        "rm rfcn_resnet101_fp32_coco_pretrained_model.tar.gz\n",
        "chmod -R 777 tmp/rfcn_resnet101_coco_2018_01_28\n",
        "mv tmp/rfcn_resnet101_coco_2018_01_28/saved_model/saved_model.pb tmp/model/1\n",
        "rm -rf tmp/rfcn_resnet101_coco_2018_01_28\n",
        "\n"
      ],
      "metadata": {
        "id": "4cAga5N9VOQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Added logger and exception handling to the files"
      ],
      "metadata": {
        "id": "ntE75BBNscsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) \tIf we want to use multiple models trained internally (not public), what would you change in the setup of the project?\n",
        "\n",
        "One suggested improvement is to modify the configuration file to enable passing multiple models and then update the object_detector.py file to iterate through the data for each of the different models. Alternatively, we could also utilize the concept of multithreading to reduce the processing time instead of looping through the data."
      ],
      "metadata": {
        "id": "5fP4zX-XSqwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''sample config.py'''\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "from adapters.count_repo import CountMySQLRepo\n",
        "from adapters.object_detector import TFSObjectDetector\n",
        "from domain.actions import CountDetectedObjects\n",
        "\n",
        "def dev_count_action() -> CountDetectedObjects:\n",
        "    tfs_host = os.environ.get('TFS_HOST', 'localhost')\n",
        "    tfs_port = os.environ.get('TFS_PORT', 8501)\n",
        "    mysql_host = os.environ.get('MYSQL_HOST', 'localhost')\n",
        "    mysql_port = os.environ.get('MYSQL_PORT', 3306)\n",
        "    mysql_user = os.environ.get('MYSQL_USER', 'root')\n",
        "    mysql_password = os.environ.get('MYSQL_PASSWORD', 'password')\n",
        "    mysql_db = os.environ.get('MYSQL_DB', 'DB')\n",
        "    models = ['rfcn', 'ssd', 'yolo']\n",
        "    return CountDetectedObjects(TFSObjectDetector(tfs_host, tfs_port, models),\n",
        "                                CountMySQLRepo(mysql_host, mysql_port, mysql_user, mysql_password, mysql_db))\n",
        "    \n",
        "    \n",
        "'''sample object_detector.py'''\n",
        "\n",
        "\n",
        "class TFSObjectDetector(ObjectDetector):\n",
        "    def __init__(self, host, port, models):\n",
        "        self.models=models\n",
        "        self.urls = {model: f\"http://{host}:{port}/v1/models/{model}:predict\" for model in models}\n",
        "        self.classes_dicts = {model: self.__build_classes_dict(model) for model in models}\n",
        "\n",
        "    def predict(self, image: BinaryIO) -> List[Prediction]:\n",
        "        np_image = self.__to_np_array(image)\n",
        "        prediction_li=[]\n",
        "        predict_request = '{\"instances\" : %s}' % np.expand_dims(np_image, 0).tolist()\n",
        "        for model in self.models:\n",
        "            response = requests.post(self.urls[model], data=predict_request)\n",
        "            predictions = response.json()['predictions'][0]\n",
        "            pred_value= self.__raw_predictions_to_domain(predictions, self.classes_dicts[model])\n",
        "            prediction_li.append(pred_value)\n",
        "        return prediction_li\n",
        "    @staticmethod\n",
        "    def __build_classes_dict(model):\n",
        "         with open('counter/adapters/mscoco_label_map.json') as json_file:\n",
        "            labels = json.load(json_file)\n",
        "            return {label['id']: label['display_name'] for label in labels}\n",
        "\n",
        "    @staticmethod\n",
        "    def __to_np_array(image: BinaryIO):\n",
        "        image_ = Image.open(image)\n",
        "        (im_width, im_height) = image_.size\n",
        "        return np.array(image_.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "    def __raw_predictions_to_domain(self, raw_predictions: dict, classes_dict: dict) -> List[Prediction]:\n",
        "        num_detections = int(raw_predictions.get('num_detections'))\n",
        "        predictions = []\n",
        "        for i in range(0, num_detections):\n",
        "            detection_box = raw_predictions['detection_boxes'][i]\n",
        "            box = Box(xmin=detection_box[1], ymin=detection_box[0], xmax=detection_box[3], ymax=detection_box[2])\n",
        "            detection_score = raw_predictions['detection_scores'][i]\n",
        "            detection_class = raw_predictions['detection_classes'][i]\n",
        "            class_name = classes_dict[detection_class]\n",
        "            predictions.append(Prediction(class_name=class_name, score=detection_score, box=box))\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "LhGeoCUBSOM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Choose one of the following:\n",
        "\n",
        "  b. Support models for object detection using different deep learning frameworks. If the task seems too big, just lay out the main key points of the proposed solution.\n",
        "\n",
        "\n",
        "\n",
        "      Let's consider we want to support two different frameworks: TensorFlow and PyTorch.\n",
        "\n",
        "We could create separate classes for each framework that implement the necessary functionality for object detection. For example, we could create a TensorFlowObjectDetector class and a PyTorchObjectDetector class.\n",
        "\n",
        "Both classes would have a detect_objects method that takes an image as input and returns a list of detected objects. However, the implementation of this method would be different for each framework.\n",
        "\n",
        "To allow users to choose which framework to use, we could create a DetectorFactory class that has a create_object_detector method. This method would take a string parameter indicating the desired framework (e.g. \"tensorflow\" or \"pytorch\") and return an instance of the appropriate object detector class.\n",
        "\n",
        "\n",
        "To detect objects using multiple models in parallel, we could use multithreading or multiprocessing. For example, we could create a separate thread or process for each model and feed images to each model in parallel. This would speed up the detection process and allow us to detect objects using multiple models at the same time.\n",
        "\n",
        "Overall, this approach would allow us to support object detection using multiple deep learning frameworks, and provide users with the flexibility to choose which framework to use."
      ],
      "metadata": {
        "id": "qvFltI5qvAFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "The specific implementation of the API can then be created for each framework.\n",
        " For example, if we want to support TensorFlow and PyTorch models for object detection, we can create two classes that implement the API for each framework.\n",
        "\n",
        "Here is an example of how the API could be designed:\n",
        "'''\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "class ObjectDetector:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        \n",
        "    def predict(self, image):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class TFSObjectDetector(ObjectDetector):\n",
        "    def __init__(self, model_path):\n",
        "        model = tf.saved_model.load(model_path)\n",
        "        super().__init__(model)\n",
        "\n",
        "    def predict(self, image):\n",
        "        # Preprocess image and get predictions using TensorFlow model\n",
        "        processed_image = preprocess_image(image)\n",
        "        predictions = self.model(processed_image)\n",
        "        return predictions\n",
        "\n",
        "class TorchObjectDetector(ObjectDetector):\n",
        "\n",
        "    def __init__(self, model_path):\n",
        "        model = torch.load(model_path)\n",
        "        super().__init__(model)\n",
        "\n",
        "    def predict(self, image):\n",
        "        # Preprocess image and get predictions using PyTorch model\n",
        "        processed_image = preprocess_image(image)\n",
        "        predictions = self.model(processed_image)\n",
        "        return predictions\n",
        "\n",
        "def preprocess_image(image):\n",
        "    # Preprocess the image according to the input requirements of the model\n",
        "    # ...\n",
        "    return \"processed_image\"\n",
        "\n",
        "image=\"abc.jpg\"\n",
        "# Example usage\n",
        "tf_detector = TFSObjectDetector('models/tf_model')\n",
        "tf_predictions = tf_detector.predict(image)\n",
        "\n",
        "torch_detector = TorchObjectDetector('models/torch_model')\n",
        "torch_predictions = torch_detector.predict(image)\n",
        "\n",
        "'''\n",
        "This approach allows us to support multiple deep learning frameworks for object detection without having to modify the rest of the codebase.'''"
      ],
      "metadata": {
        "id": "Y5i6Y7IEu-4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}